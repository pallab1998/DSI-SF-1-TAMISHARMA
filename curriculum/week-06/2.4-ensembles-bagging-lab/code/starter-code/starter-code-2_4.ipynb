{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees and Ensembles Lab\n",
    "\n",
    "In this lab we will compare the performance of a simple Decision Tree classifier with a Bagging classifier. We will do that on few datasets, starting from the ones offered by Scikit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Breast Cancer Dataset\n",
    "We will start our comparison on the breast cancer dataset.\n",
    "You can load it directly from scikit-learn using the `load_breast_cancer` function.\n",
    "\n",
    "### 1.a Simple comparison\n",
    "1. Load the data and create X and Y.\n",
    "- Initialize a Decision Tree Classifier and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds.\n",
    "- Wrap a Bagging Classifier around the Decision Tree Classifier and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds. \n",
    "- Which score is better? Are the score significantly different? How can you judge that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.1189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0           0.1184   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0            0.2776          0.3001               0.1471         0.2419   \n",
       "\n",
       "   mean fractal dimension           ...             worst radius  \\\n",
       "0                 0.07871           ...                    25.38   \n",
       "\n",
       "   worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0          17.33            184.6      2019.0            0.1622   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "\n",
       "   worst fractal dimension  \n",
       "0                   0.1189  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.datasets as dataloader\n",
    "\n",
    "bcancer = dataloader.load_breast_cancer()\n",
    "Xb = pd.DataFrame(bcancer.data, columns = bcancer.feature_names)\n",
    "Yb = pd.DataFrame(bcancer.target)\n",
    "\n",
    "Xb.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>map</th>\n",
       "      <th>tc</th>\n",
       "      <th>ldl</th>\n",
       "      <th>hdl</th>\n",
       "      <th>tch</th>\n",
       "      <th>ltg</th>\n",
       "      <th>glu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.05068</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age      sex       bmi       map        tc       ldl       hdl  \\\n",
       "0  0.038076  0.05068  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "\n",
       "        tch       ltg       glu  \n",
       "0 -0.002592  0.019908 -0.017646  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = dataloader.load_diabetes()\n",
    "\n",
    "diabetes_columns = ['age', 'sex', 'bmi', 'map', 'tc', 'ldl', 'hdl', 'tch', 'ltg', 'glu']\n",
    "\n",
    "Xd = pd.DataFrame(diabetes.data, columns = diabetes_columns)\n",
    "Yd = pd.DataFrame(diabetes.target)\n",
    "\n",
    "Xd.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
      "['age', 'sex', 'bmi', 'map', 'tc', 'ldl', 'hdl', 'tch', 'ltg', 'glu']\n"
     ]
    }
   ],
   "source": [
    "print list(Xb.columns)\n",
    "print list(Xd.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import patsy\n",
    "\n",
    "Xb = patsy.dmatrix('~ mean radius + mean texture + mean perimeter + mean area + mean smoothness + mean compactness + mean concavity + mean concave points + mean symmetry + mean fractal dimension')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b Scale (normalize) data\n",
    "As you may have noticed the features are not normalized. Do the score improve with normalization?\n",
    "\n",
    "1. Normalize the predictors.\n",
    "2. Build a decision tree classifier and bagging decision tree classifier.\n",
    "3. Are scores different from non-scaled data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age   -0.039522\n",
      "sex   -0.937474\n",
      "bmi   -1.080955\n",
      "map   -0.552885\n",
      "tc    -0.177423\n",
      "ldl   -0.402430\n",
      "hdl    1.562643\n",
      "tch   -0.829361\n",
      "ltg   -1.434925\n",
      "glu   -1.936285\n",
      "Name: 1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# version 1:\n",
    "Xd = (Xd - Xd.mean()) / Xd.std()\n",
    "\n",
    "# alternate scaling version:\n",
    "ss = StandardScaler()\n",
    "x_norm = pd.DataFrame(ss.fit_transform(Xd.values), columns = Xd.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c Grid Search\n",
    "\n",
    "Grid search is a great way to improve the performance of a classifier. Let's explore the parameter space of both models and see if we can improve their performance.\n",
    "\n",
    "1. Initialize a GridSearchCV with 5-fold cross validation for the Decision Tree Classifier.\n",
    "2. Search for few parameter values to try and improve the score of the classifier.\n",
    "4. Check the best\\_score\\_ once you've trained it. Is it better than before?\n",
    "5. How does the score of the Grid-searched DT compare with the score of the Bagging DT?\n",
    "6. Initialize a GridSearchCV with 5-fold cross validation for the Bagging Decision Tree Classifier\n",
    "7. Repeat the search\n",
    "    - Note that you'll have to change parameter names for the base_estimator (see example).\n",
    "    - Note that there are also additional parameters to change (see example).\n",
    "    - Note that you may end up with a grid space to large to search in a short time - choose smaller ranges of parameters!\n",
    "    - Make use of the n_jobs parameter to speed up your grid search (-1 uses all cores).\n",
    "8. Does the score improve for the Grid-searched Bagging Classifier?\n",
    "9. Which score is better? Are the score significantly different? How could/would you judge that?\n",
    "\n",
    "---\n",
    "\n",
    "**EXAMPLE**\n",
    "```python\n",
    "params = {\"base_estimator__max_depth\": [3,5,10,20],\n",
    "          \"base_estimator__max_features\": [None, \"auto\"],\n",
    "          \"base_estimator__min_samples_leaf\": [1, 3, 5, 7, 10],\n",
    "          \"base_estimator__min_samples_split\": [2, 5, 7],\n",
    "          'bootstrap_features': [False, True],\n",
    "          'max_features': [0.5, 0.7, 1.0],\n",
    "          'max_samples': [0.5, 0.7, 1.0],\n",
    "          'n_estimators': [2, 5, 10, 20],\n",
    "         }\n",
    "\n",
    "bagged_decision_trees = BaggingClassifier(DecisionTreeClassifier())\n",
    "\n",
    "gsbdt = GridSearchCV(bagged_decision_trees, params, n_jobs=-1, cv=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Diabetes and Regression\n",
    "\n",
    "Scikit Learn has a dataset of diabetic patients obtained from this study:\n",
    "\n",
    "http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
    "http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf\n",
    "\n",
    "442 diabetes patients were measured on 10 baseline variables: age, sex, body mass index, average blood pressure, and six blood serum measurements.\n",
    "\n",
    "The target is a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "Repeat the above comparison between a DecisionTreeRegressor and a Bagging Regressor instead of classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a Simple comparison\n",
    "1. Load the data and create X and Y\n",
    "2. Initialize a Decision Tree Regressor and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds. What does the score mean (look at documentation!).\n",
    "3. Wrap a Bagging Regressor around the Decision Tree Regressor and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds. \n",
    "4. Which score is better? Are the score significantly different? How could/would you judge that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b Grid Search\n",
    "\n",
    "Repeat Grid search as above:\n",
    "\n",
    "1. Initialize a GridSearchCV with 5-fold cross validation for the Decision Tree Regressor.\n",
    "2. Search for few values of the parameters in order to improve the score of the regressor.\n",
    "3. Check the best\\_score\\_ once you've trained it. Is it better than before?\n",
    "4. How does the score of the Grid-searched DT compare with the score of the Bagging DT?\n",
    "5. Initialize a GridSearchCV with 5-fold cross validation for the Bagging Decision Tree Regressor\n",
    "6. Repeat the search\n",
    "    - Note that you'll have to change parameter names for the base_estimator.\n",
    "    - Note that there are also additional parameters to change.\n",
    "    - Note that you may end up with a grid space to large to search in a short time.\n",
    "    - Make use of the n_jobs parameter to speed up your grid search.\n",
    "7. Does the score improve for the Grid-searched Bagging Regressor?\n",
    "8. Which score is better? Are the score significantly different? How could/would you judge that?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [BONUS]: Project 5 data\n",
    "\n",
    "Repeat the appropriate analysis (classification/regression) for the Project 5 Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
