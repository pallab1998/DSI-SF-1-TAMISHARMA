{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"https://i.imgflip.com/14vp9i.jpg\" width=\"400\" style=\"float: right; margin: 50px\">\n",
    "\n",
    "# GROUP EDA\n",
    "\n",
    "Today we will be splitting into 4 groups and presenting our findings the last hour of class.\n",
    "\n",
    "The goals for todays activity include:\n",
    "\n",
    "- Defining a problem statement as a group\n",
    "- Exloring datasets and practicing exploratory analysis \n",
    "- Good use of validation\n",
    "- Communicating results succinctly\n",
    "\n",
    "You might consider preparing a brief slide deck, but it's not necessary.  We created [these great guidelines](https://github.com/ga-students/DSI-SF-1/wiki/Presentation-Guidelines) to help.\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "- 10 Minute presentation, 5 minutes question and answer\n",
    "- Validation of results\n",
    "\n",
    "### Optional Feedback\n",
    "\n",
    "After presentations, please give feedback to each other.\n",
    "\n",
    "- Peer feedback:  [Use this form](http://goo.gl/forms/ybRIcrwYrVVV4hhR2).  All responses are shared.  Be nice ;)\n",
    "\n",
    "### Suggestions\n",
    "- Appoint someone to present / organize\n",
    "- Look at summary statistics, explore data\n",
    "- Refine problem statement\n",
    "- Divide and conquer your workload\n",
    "- Don't fight - you will be held accountable for presenting _something_.\n",
    "- You will present\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 1:  WOW\n",
    "\n",
    "<img src=\"https://snag.gy/tZXe0N.jpg\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using [this dataset](https://www.kaggle.com/mylesoneill/warcraft-avatar-history/downloads/warcraft-avatar-history.zip), we would like you to figure out if the following is possible:\n",
    " \n",
    "1. Predict when a user has \"churned\" or will churn.  We want to know about churn!  What is this about, you will have to research this idea if it is unfamilliar to you.  We want that \\$\\$\\$\\$ so help us deal with churn!<br><br>\n",
    "\n",
    "1. Also, we want to know more about zones and player classes.  We have a hunch something good is happening there.<br><br>\n",
    "\n",
    "1. Is there anything else we can do to optimize gameplay?<br><br>\n",
    "\n",
    "1. We're thinking about making yet another expansion.  Are there any themes we might consider based on player behavior *ie: which features are important to consider about current player preferences to ______*?\n",
    "\n",
    "** Projected Challenges **\n",
    "- Research\n",
    "- Problem statement expected to be much more defined\n",
    "- There are a lot of areas to explore and focus may be difficult without a plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 2: GOT\n",
    "\n",
    "<img src=\"https://snag.gy/8uoD9y.jpg\" width=\"500\">\n",
    "\n",
    "Using [this dataset](./assets/datasets/character-predictions.csv), we would like to know which factors are most important predictors of mortality within our population.  From what we know, this dataset was scraped from [this website](http://awoiaf.westeros.org/index.php/Main_Page) and may provide pointers on the definition of the dataset.\n",
    "\n",
    "**Projected Challeneges**\n",
    "- Some munging\n",
    "- Regression and classification type problems possible\n",
    "- Data is not as cut and dry as it seems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 3:  Last Words\n",
    "\n",
    "<img src=\"https://snag.gy/MElcUY.jpg\" width=\"200\">\n",
    "\n",
    "Using [this dataset](https://docs.google.com/spreadsheet/ccc?key=0ArNsipRBvi69dEUxZHVuRTc4ZlctREdldExsOW5rMUE#gid=0), we would like you to approach this as a study that might inform policy in how law is applied.  The first step in this process, let's assume, is a high level report that illustrates any commonalities and patterns found in this dataset\n",
    ":\n",
    "\n",
    "- Common patterns found in last words of inmates\n",
    "- Commonality of words to other features in dataset\n",
    "- Of lessor importance, how hard would it be to classify religious inclinations\n",
    "- Sentiment as a feature or frequency (ie: Check out textblob - pip install textblob)\n",
    " - Can this be stratified to other features\n",
    " - Which words seem to be common in these cases\n",
    "\n",
    "** Bonus **\n",
    "Do any POS patterns look interesting?\n",
    "\n",
    "**Projected Challenges**\n",
    " - Problem statement may be challenging but you will need to come up with one\n",
    " - This project is a bit more defined but there are vague problems involved\n",
    " - There are a lot of vague asks\n",
    " - Heavily NLP based problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 4: Indeed, you need a job\n",
    "\n",
    "<img src=\"https://lh5.googleusercontent.com/CJwGV91wfvsEsDqCBjsg2ahGKAoP2_Wwd3JXXBb8yWPlIT676LlBnsIfG2bFUtOxgLb0ba5WJKfzMiVdT9ncQhSmscdcxPZDnWfV6Qkb0LhR_6Natug72_MsYTLDJS34vg\" width=\"500\">\n",
    "\n",
    "You need a job.  There are lots of jobs with the title \"Data Scientist\".  There are other jobs as well that have the same skillset.  Recently we [scraped together a dataset](assets/datasets/indeed.csv), that is not super clean but will work.\n",
    "\n",
    "Which jobs aren't labeled like \"data science\" jobs, but have a lot of the same features found in \"data scientist\" jobs?\n",
    "\n",
    " - Who is hiring the most? (this may be difficult without updating our scraper and getting more data, but we'll say this is optional)\n",
    " - Which skills seem more important to big / medium / small companies or less well known?\n",
    " - Which keywords are commmon?\n",
    " - Which are rare?\n",
    "\n",
    "**Projected Challenges**\n",
    "- Labeled data is based on search terms and results may overlap quite a bit\n",
    " - Some cleaning\n",
    "- Great opportunity to practice NLP\n",
    "- DO NGRAM ANALYSIS OR ELSE!\n",
    "\n",
    "PLEASE share your notebooks with the rest of class.  This type of analysis will give you an edge in the job market and lead you to other areas to explore / mine / predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indeed = pd.read_csv('assets/datasets/indeed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>search_term</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18 reviews</td>\n",
       "      <td>business intelligence</td>\n",
       "      <td>Data Warehouse Development Senior Manager</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>Proficiency fostering internal and external bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,486 reviews</td>\n",
       "      <td>business intelligence</td>\n",
       "      <td>Manager, Healthcare Business Intelligence</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Experience working with BI tools such as such ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14 reviews</td>\n",
       "      <td>business intelligence</td>\n",
       "      <td>Business Intelligence Developer</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>Work with BI Administrator and Architect to le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90 reviews</td>\n",
       "      <td>business intelligence</td>\n",
       "      <td>Business Intelligence Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nOur business is growing and we always lookin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11 reviews</td>\n",
       "      <td>business intelligence</td>\n",
       "      <td>Sr Business Intelligence Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nWe have a great opportunity available for a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         reviews            search_term  \\\n",
       "0     18 reviews  business intelligence   \n",
       "1  1,486 reviews  business intelligence   \n",
       "2     14 reviews  business intelligence   \n",
       "3     90 reviews  business intelligence   \n",
       "4     11 reviews  business intelligence   \n",
       "\n",
       "                                       title           location  \\\n",
       "0  Data Warehouse Development Senior Manager  Mountain View, CA   \n",
       "1  Manager, Healthcare Business Intelligence  San Francisco, CA   \n",
       "2            Business Intelligence Developer  Mountain View, CA   \n",
       "3              Business Intelligence Analyst                NaN   \n",
       "4           Sr Business Intelligence Analyst                NaN   \n",
       "\n",
       "                                             summary  \n",
       "0  Proficiency fostering internal and external bu...  \n",
       "1  Experience working with BI tools such as such ...  \n",
       "2  Work with BI Administrator and Architect to le...  \n",
       "3  \\nOur business is growing and we always lookin...  \n",
       "4  \\nWe have a great opportunity available for a ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "software engineer        1497\n",
       "analytics                1497\n",
       "Data Engineer            1494\n",
       "Data Analyst             1484\n",
       "Data Scientist           1379\n",
       "business intelligence    1360\n",
       "search_term                 5\n",
       "Name: search_term, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed.search_term.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec = CountVectorizer()\n",
    "cvec.fit(indeed.summary.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-a6e7c84a8477>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df  = pd.DataFrame(cvec.transform([indeed.summary.values]).todense(),\n\u001b[0m\u001b[1;32m      2\u001b[0m              columns=cvec.get_feature_names())\n",
      "\u001b[0;32m/Users/Tami/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Tami/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mj_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Tami/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 238\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Tami/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "df  = pd.DataFrame(cvec.transform([indeed.summary.values]).todense(),\n",
    "             columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_corpus = \"\"\n",
    "\n",
    "for item in indeed.summary:\n",
    "    summary_corpus += item\n",
    "    \n",
    "summary_corpus = unicode(summary_corpus, errors='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "en_nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_ = en_nlp(summary_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "named_ents = summary_.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Python, HTML5, News, Google, HTML5, Python, HTML5, Google, Google, Google)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_ents[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "753"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(named_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "named_list = []\n",
    "\n",
    "for name in named_ents:\n",
    "    if name not in named_list:\n",
    "        named_list.append(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
